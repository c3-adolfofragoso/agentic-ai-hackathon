/*
 * Copyright 2009-2024 C3 AI (www.c3.ai). All Rights Reserved.
 * Confidential and Proprietary C3 Materials.
 * This material, including without limitation any software, is the confidential trade secret and proprietary
 * information of C3 and its licensors. Reproduction, use and/or distribution of this material in any form is
 * strictly prohibited except as set forth in a written license agreement with C3 and/or its authorized distributors.
 * This material may be covered by one or more patents or pending patent applications.
 */

/**
 * This type creates {@link MlAtomicPipe} that can extract SentenceBERT
 * language model embeddings given a list of texts.
 */
type Embedding.Extraction.SentenceBertPipe extends Embedding.Extraction.Pipe type key 'EESBP' {

  /**
   * The name of the pre-trained language models to get the embeddings.
   * Please refer to the pre-trained models here: https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models/
   */
  /*
   * TODO ESG-3875: Create a validation check for the models used by the sentence BERT pipe.
   */
  modelName: !string

  /**
   * The maximum number of tokens per sentence/paragraph to be encoded.
   * See further details here
   * https://www.sbert.net/examples/applications/computing-embeddings/README.html.
   */
  maxSequenceLength: int = 512

  /**
   * Load pre-trained model and tokenizer.
   */
  doTrain: ~ py-embedding

  /**
   * Extract embeddings from large pre-trained SentenceBERT language models
   * given the input as a list of text.
   * The {@link MlPipeline} will use GPU resources if they are available at inference time.
   * In the function, `this.setFeatureIndices` is used to set the subject feature as the index, which
   * will be used by downstream pipes as well.
   */
  doProcess: ~ py-embedding

  /**
   * Save pre-trained model and tokenizer using predefined APIs.
   */
  saveModel: ~ py-embedding

  /**
   * Load pre-trained model and tokenizer using predefined APIs.
   */
  loadModel: ~ py-embedding
}
